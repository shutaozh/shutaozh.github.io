
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Han - Department of Computer Science and Technology, Tsinghua University </title>
    <meta name="description" content="I am a Ph.D. student in the Department of Computer Science and Technology at Tsinghua University, advised by Professor Zhiyuan Liu. My research interests focus on the intersection of natural language processing, deep learning and computer systems.">
    <meta name="keywords" content="Xu Han, THU, Tsinghua University, CST, Department of Computer Science and Technology, NLP, Natural Language Processing, DL, Deep Learning, Computer Systems, Homepage">
    <meta name="author" content="Xu Han">
    <link rel="icon" href="static/logo.jpg">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font.css">
    <link rel="stylesheet" href="css/font-awesome.css">
    <link rel="stylesheet" href="css/custom.css">
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>

  </head>

  <body>
  <div class="container" align="justify">
    <div class="row">
        <div class="col-5">
            <img src="static/portrait.jpg" class="img-responsive" style="width:82%; border-radius: 0%;">
        </div>
        <div class="col-7">
            <h3>Xu Han</h3>
            <p>
                <a href="static/cv.pdf" target="_blank">[CV]</a>&nbsp;&nbsp;
                <a href="https://scholar.google.com/citations?user=rz4rOSMAAAAJ&hl=zh-CN" target="_blank">[Scholar]</a>
            </p>
            <p>
                <table>
                    <tr><td>Ph.D. Student</tr>
                    <tr><td><a href="http://nlp.csai.tsinghua.edu.cn/">Natural Language Processing Lab,</a></td></tr>
                    <tr><td><a href="http://www.cs.tsinghua.edu.cn/">Department of Computer Science and Technology,</a></td></tr>
                    <tr><td><a href="http://www.tsinghua.edu.cn/publish/thu2018/index.html">Tsinghua University</a>, Beijing, China.</td></tr>
                </table>
            </p>
            <p>
                <table>
                    <tr><td><b>Email:</b>&nbsp;</td><td>thu&nbsp;[dot]&nbsp;hanxu13&nbsp;[at]&nbsp;gmail&nbsp;[dot]&nbsp;com</td></tr>
                    <tr><td></td><td>cst_hanxu13&nbsp;[at]&nbsp;163&nbsp;[dot]&nbsp;com</td></tr>
                    <tr><td><b>Office:</b>&nbsp;</td><td>Room 4-506, FIT Building, Tsinghua University</td></tr>
                    <tr><td></td><td>Beijing, 100084, China</td></tr> 
                    <tr><td><b>Github:</b>&nbsp;</td><td><a href="https://github.com/thucsthanxu13">THUCSTHanxu13</a></td></tr>
                </table>
            </p>
        </div>
    </div>

    <br/>
    
    <h5>About Me</h5>
    <p>
        Hi! I am a Ph.D. student in the 
        <a href="http://www.cs.tsinghua.edu.cn/" target="_blank"><b>Department of Computer Science and Technology</b></a> 
        at 
        <a href="http://www.tsinghua.edu.cn/publish/thu2018/index.html" target="_blank"><b>Tsinghua University</b></a>. 
        I am advised by 
        <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/" target="_blank"><b>Professor Zhiyuan Liu</b></a> 
        and affiliated with the 
        <a href="http://thunlp.org/site2/" target="_blank"><b>THUNLP</b></a>. 
        My research interests lie within the intersection of natural language processing, deep learning, information extraction and knowledge graphs. Before I becoming a Ph.D. student, I also received my bachelor degree from Tsinghua University</a>.
    </p>

    <hr/>

    <h5>Projects</h5>
        <ul>
            <li><a href="https://github.com/thunlp/OpenKE">OpenKE</a></li>
            <li><a href="https://github.com/thunlp/OpenNRE">OpenNRE</a></li>
            <li><a href="https://github.com/thunlp/FewRel">FewRel</a></li>
            <li><a href="https://github.com/thunlp/TensorFlow-TransX">TensorFlow-TransX</a></li>
            <li><a href="https://github.com/thunlp/Fast-TransX">Fast-TransX</a></li>
            <li><a href="https://github.com/thunlp/KRLPapers">KRLPapers</a></li>
            <li><a href="https://github.com/thunlp/NREPapers">NREPapers</a></li>
        </ul>
    


    <hr/>

    <h5>Publications</h5>
    
<!--     <div class="gap">
        <br>
    </div>
 -->
<!--     <div type="button" class="jumbotron" style="background-color:#ffffff;margin-bottom:5px;" data-toggle="collapse" 
            data-target="#denoisingDRE">
        <h6 style="text-align:left;">Denoising Distant Supervision for Relation Extraction via Instance-Level Adversarial Training. 2018.</h6>
        <div class="jumbotron collapse in" id="denoisingDRE">
            <b>Abstract:</b>
            <p>Existing neural relation extraction (NRE) models rely on distant supervision and suffer from wrong labeling problems. In this paper, we propose a novel adversarial training mechanism over instances for relation extraction to alleviate the noise issue. As compared with previous denoising methods, our proposed method can better discriminate those informative instances from noisy ones. Our method is also efficient and flexible to be applied to various NRE architectures. As shown in the experiments on a large-scale benchmark dataset in relation extraction, our denoising method can effectively filter out noisy instances and achieve significant improvements as compared with the state-of-the-art models.
            </p>
            <p>
            <b>Papers:</b>
            <br/>
            <a href="https://arxiv.org/pdf/1805.10959.pdf" target="_blank">Denoising Distant Supervision for Relation Extraction via Instance-Level Adversarial Training.</a> 
            </p>
        </div>
    </div>


    <div type="button" class="jumbotron" style="background-color:rgb(0,0,255);margin-bottom:5px;" data-toggle="collapse" 
            data-target="#AMNRE">
        <h6 style="text-align:left;">Adversarial Multi-lingual Neural Relation Extraction. COLING 2018.</h6>
        <div class="jumbotron collapse in" id="AMNRE">
            <b>Abstract:</b>
            <p>Multi-lingual relation extraction aims to find unknown relational facts from text in various languages. Existing models cannot well capture the consistency and diversity of relation patterns in different languages. To address these issues, we propose an adversarial multi-lingual neural relation extraction (AMNRE) model, which builds both consistent and individual representations for each sentence to consider the consistency and diversity among languages. Further, we adopt an adversarial training strategy to ensure those consistent sentence representations could effectively extract the language-consistent relation patterns. The experimental results on real-world datasets demonstrate that our AMNRE model significantly outperforms the state-of-the-art models.
            </p>
            <p>
            <b>Papers:</b>
            <br/>
            <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/publications/coling2018_amnre.pdf" target="_blank">Adversarial Multi-lingual Neural Relation Extraction.</a> (<b>COLING 2018</b>)
            </p>
            <p>
            <b>Code:</b>
            <br/>
            <a href="https://github.com/thunlp/AMNRE" target="_blank">[AMNRE]</a>
            </p>
        </div>
    </div>

    <div type="button" class="jumbotron" style="background-color:rgb(255,255,255);margin-bottom:5px;" data-toggle="collapse" 
            data-target="#JointNRE">
        <h6 style="text-align:left;">Neural Knowledge Acquisition via Mutual Attention between Knowledge Graph and Text. AAAI 2018.</h6>
        <div class="jumbotron collapse in" id="JointNRE">
            <b>Abstract:</b>
            <p>We propose a general joint representation learning framework for knowledge acquisition (KA) on two tasks, knowledge graph completion (KGC) and relation extraction (RE) from text. In this framework, we learn representations of knowledge graphs (KGs) and text within a unified parameter sharing semantic space. To achieve better fusion, we propose an effective mutual attention between KGs and text. The reciprocal attention mechanism enables us to highlight important features and perform better KGC and RE. Different from conventional joint models, no complicated linguistic analysis or strict alignments between KGs and text are required to train our models. Experiments on relation extraction and entity link prediction show that models trained under our joint framework are significantly improved in comparison with other baselines. Most existing methods for KGC and RE can be easily integrated into our framework due to its flexible architectures.</p>
            <p>
            <b>Papers:</b>
            <br/>
            <a href="https://arxiv.org/abs/1711.11135" target="_blank">Neural Knowledge Acquisition via Mutual Attention between Knowledge Graph and Text</a> (<b>AAAI 2018</b>)
            </p>
            <p>
            <b>Code:</b>
            <br/>
            <a href="https://github.com/thunlp/JointNRE" target="_blank">[JointNRE]</a>
            </p>
            </p>
        </div>
    </div>

 -->



    <p>
        <table>

            <tr><td>1. &nbsp; <b>Xu Han</b>, Tianyu Gao, Yuan Yao, Demin Ye, Zhiyuan Liu, Maosong Sun.
            OpenNRE: An Open and Extensible Toolkit for Neural Relation Extraction. EMNLP 2019. Demo paper. 
            </td></tr>
            <tr><td>2. &nbsp;
            Ruidong Wu, Yuan Yao,  <b>Xu Han</b>, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin, Maosong Sun. Open Relation Extraction: Relational Knowledge Transfer from Supervised Data to Unsupervised Data. EMNLP 2019. Long paper. 
            </td></tr>
            <tr><td>3. &nbsp;
            Tianyu Gao,  <b>Xu Han</b>, Hao Zhu, Zhiyuan Liu , Peng Li, Maosong Sun, Jie Zhou. FewRel 2.0: Towards More Challenging Few-Shot Relation Classification. EMNLP 2019. Short paper.
            </td></tr>            
            <tr><td>4. &nbsp;
            Xiaozhi Wang, Ziqi Wang,  <b>Xu Han</b>, Zhiyuan Liu, Juanzi Li, Peng Li, Maosong Sun, Jie Zhou, Xiang Ren. HMEAE: Hierarchical Modular Event Argument Extraction. EMNLP 2019. Short paper.
            </td></tr>
            <tr><td>5. &nbsp;
            Xin Lv, Yuxian Gu,  <b>Xu Han</b>, Lei Hou, Juanzi Li, Zhiyuan Liu. Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over Few-Shot Relations. EMNLP 2019. Short paper.
            </td></tr>

            <tr><td>6. &nbsp;Zhengyan Zhang, <b>Xu Han*</b>, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu (* indicates equal contribution). ERNIE: Enhanced Language Representation with Informative Entities. ACL 2019. Long paper. </td></tr>
            <tr><td>7. &nbsp;Jie Zhou, <b>Xu Han</b>, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, Maosong Sun. GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification. ACL 2019. Long paper. </td></tr>
            <tr><td>8. &nbsp;Yuan Yao, Deming Ye, Peng Li, <b>Xu Han</b>, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, Maosong Sun. DocRED: A Large-Scale Document-Level Relation Extraction Dataset. ACL 2019. Long paper. </td></tr>
            <tr><td>9. &nbsp; Weize Chen, Hao Zhu, <b>Xu Han</b>, Zhiyuan Liu, Maosong Sun. Quantifying Similarity between Relations with Fact Distribution. ACL 2019. Long paper.</td></tr>
            <tr><td>10. &nbsp; Shun Zheng, Xu Han, Yankai Lin, Peilin Yu, Lu Chen, Ling Huang, Zhiyuan Liu, Wei Xu. DIAG-NRE: A Neural Pattern Diagnosis Framework for Distantly Supervised Neural Relation Extraction. ACL 2019. Long paper.
            </td></tr>
            <tr><td>11. &nbsp;Xiaozhi Wang*, <b>Xu Han*</b>, Zhiyuan Liu, Maosong Sun, Peng Li (* indicates equal contribution). Adversarial Training for Weakly Supervised Event Detection. NAACL-HLT 2019. Long paper.</td></tr>
            <tr><td>12. &nbsp;Tianyu Gao*, <b>Xu Han*</b>, Zhiyuan Liu, Maosong Sun (* indicates equal contribution). Hybrid Attention-based Prototypical Networks for Noisy Few-Shot Relation Classification. AAAI 2019. Long paper.</td></tr>
            <tr><td>13. &nbsp;<b>Xu Han</b>, Pengfei Yu, Zhiyuan Liu, Maosong Sun, Peng Li. Hierarchical Relation Extraction with Coarse-to-Fine Grained Attention. EMNLP 2018. Long paper.</td></tr>
            <tr><td>14. &nbsp;<b>Xu Han</b>, Shulin Cao, Xin Lv, Yankai Lin, Zhiyuan Liu, Maosong Sun and Juanzi Li. OpenKE: An Open Toolkit for Knowledge Embedding. EMNLP 2018. Demo paper.</td></tr>
            <tr><td>15. &nbsp;<b>Xu Han</b>, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, Maosong Sun. FewRel: A Large-Scale Supervised Few-shot Relation Classification Dataset with State-of-the-Art Evaluation. EMNLP 2018. Short paper.</td></tr>
            <tr><td>16. &nbsp;Ji Xin, Hao Zhu, <b>Xu Han</b>, Zhiyuan Liu, Maosong Sun. Put It Back: Entity Typing with Language Model Enhancement. EMNLP 2018. Short paper.</td></tr>
            <tr><td>17. &nbsp;<b>Xu Han</b>, Zhiyuan Liu, Maosong Sun. Denoising Distant Supervision for Relation Extraction via Instance-Level Adversarial Training. arXiv. 2018.</td></tr>
            <tr><td>18. &nbsp;Xiaozhi Wang*, <b>Xu Han*</b>, Yankai Lin, Zhiyuan Liu, Maosong Sun (* indicates equal contribution). Adversarial Multi-lingual Neural Relation Extraction. COLING 2018. Long paper.</td></tr>
            <tr><td>19. &nbsp;<b>Xu Han</b>, Zhiyuan Liu, Maosong Sun. Neural Knowledge Acquisition via Mutual Attention between Knowledge Graph and Text. AAAI 2018. Long paper.</td></tr>
            <tr><td>20. &nbsp;<b>Xu Han</b>, Zhiyuan Liu, Maosong Sun. Joint Representation Learning of Text and Knowledge for Knowledge Graph Completion. arXiv. 2016.</td></tr>
            
        </table>
    </p>





    <hr/>

    <h5>Education and Experience</h5>
    <p>
        <table>
            <tr><td><b>[08.2017-present.]&nbsp;</b></td><td>Ph.D. student, Dept. of CS&T, Tsinghua University, Beijing, China.</td></tr>
            <tr><td><b>[08.2013-07.2017.]&nbsp;</b></td><td>B.S., Dept. of CS&T, Tsinghua University, Beijing, China.</td></tr>
            <tr><td><b>[08.2010-07.2013.]&nbsp;</b></td><td>Dafeng High School, Yancheng, Jiangsu, China.</td></tr>
            <tr><td><b>PC Member:&nbsp;</b></td><td>SIGIR 2018, IJCAI 2018, AAAI 2019, NAACL-HLT 2019, EMNLP-IJCNLP 2019.</td></tr>
        </table>
    </p>

    <hr/>

    <h5>Honors and Awards </h5>
    <p>
        <table>
            <tr><td><b>[2019.]&nbsp;</b></td><td> National Scholarship for Ph.D Student, Tsinghua University.</td></tr>
            <tr><td><b>[2018.]&nbsp;</b></td><td> National Scholarship for Ph.D Student, Tsinghua University.</td></tr>
            <tr><td><b>[2017.]&nbsp;</b></td><td> Excellent Graduate, Tsinghua University.</td></tr>
            <tr><td><b>[2017.]&nbsp;</b></td><td> Excellent Bachelor Thesis, Tsinghua University.</td></tr>
            <tr><td><b>[2017.]&nbsp;</b></td><td> Excellent Graduate, Dept. of CS&T, Tsinghua University.</td></tr>
            <tr><td><b>[2016.]&nbsp;</b></td><td> First-class Overall Excellence Scholarship, Tsinghua University.</td></tr>
            <tr><td><b>[2015.]&nbsp;</b></td><td> First-class Science and Technology Innovation Excellence Scholarship, Tsinghua University.</td></tr>
            <tr><td><b>[2014.]&nbsp;</b></td><td> First-class Academic Excellence Scholarship, Tsinghua University.</td></tr>
            <tr><td><b>[2012.]&nbsp;</b></td><td> Silver medal in National Olympiad in Information, China.</td></tr>
            <tr><td><b>[2011.]&nbsp;</b></td><td> Golden medal in National Olympiad in Information, China.</td></tr>
        </table>
    </p>

    <hr/>

    <h5>Teaching </h5>
    <p>
        <table>
            <tr><td><b>[2018-present.]&nbsp;</b></td><td> Head TA for Object-Oriented Programming, Tsinghua University.</td></tr>
            <tr><td><b>[2017.]&nbsp;</b></td><td> TA for Object-Oriented Programming, Tsinghua University.</td></tr>
            <tr><td><b>[2016.]&nbsp;</b></td><td> TA for Software Engineering, Tsinghua University.</td></tr>
        </table>
    </p>

    <hr/>

    <h5>Miscellaneous</h5>
    <p>
        <ul>
            <li>My name in Chinese is 韩旭.</li>
            <li>I come from <a href="https://en.wikipedia.org/wiki/Yancheng">Yancheng, Jiangsu, China.</a></li>
            <li> Whenever I am not doing research, I love to read, travel, and play games. My favourite games are DOTA2, Age of Empires (AOE), Hearts of Iron (HOI), and Sangokushi.
        </ul>
    </p>

    <hr/>

  </div>
    
  </body>
</html>
